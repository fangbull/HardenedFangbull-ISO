#!/bin/bash

# Zombie Process Hunter - Hardened Fangbull
# Advanced detection and elimination of zombie processes with memory-safe operations

# Source common functions
if [ -f "/usr/local/bin/common_functions.sh" ]; then
    source "/usr/local/bin/common_functions.sh"
fi

# Configuration with memory limits
LOG_FILE="/var/log/fangbull-ids/zombie.log"
LOG_MAX_SIZE=5242880  # 5MB max log size
HISTORY_FILE="/var/log/fangbull-ids/zombie_history.json"
STATS_FILE="/var/log/fangbull-ids/zombie_stats.json"
SCAN_INTERVAL=45      # Seconds between scans
MAX_HISTORY_SIZE=500  # Limit history entries to prevent memory bloat
ALERT_THRESHOLD=10    # Alert threshold for high zombie count
MAX_ZOMBIES_PER_SCAN=100  # Safety limit for zombies processed per scan
MAX_BUFFER_SIZE=16384  # Maximum buffer size for commands (16KB)
MAX_LOG_ENTRIES=1000   # Maximum log entries to keep in memory

# Create required directories with safe permissions
mkdir -p "$(dirname "$LOG_FILE")" 2>/dev/null
chmod 750 "$(dirname "$LOG_FILE")" 2>/dev/null

# Rotate log if it exceeds max size
rotate_log() {
    if [ -f "$LOG_FILE" ] && [ $(stat -c%s "$LOG_FILE" 2>/dev/null || echo 0) -gt $LOG_MAX_SIZE ]; then
        local timestamp=$(date +%Y%m%d%H%M%S)
        local backup_file="$LOG_FILE.$timestamp"
        
        # Use temporary file for atomic operations
        cp "$LOG_FILE" "$LOG_FILE.tmp" 2>/dev/null
        mv "$LOG_FILE.tmp" "$backup_file" 2>/dev/null
        
        # Compress with size limit check
        if [ -f "$backup_file" ] && [ $(stat -c%s "$backup_file" 2>/dev/null || echo 0) -lt $((LOG_MAX_SIZE*2)) ]; then
            gzip -f "$backup_file" 2>/dev/null
        fi
        
        # Truncate original log file safely
        : > "$LOG_FILE"
        chmod 640 "$LOG_FILE" 2>/dev/null
    fi
}

# Memory-safe logging function
log_message() {
    # Only log critical events
    if [ "$2" = "CRITICAL" ]; then
        local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
        local message="${1:0:1024}"  # Truncate message to prevent buffer overflow
        echo "[$timestamp] $message" >> "$LOG_FILE"
        rotate_log
    fi
}

# Load stats with error handling and size limits
load_stats() {
    if [ -f "$STATS_FILE" ] && [ $(stat -c%s "$STATS_FILE" 2>/dev/null || echo 0) -lt 1048576 ]; then
        if command -v jq >/dev/null 2>&1; then
            # Validate JSON before parsing
            if jq empty "$STATS_FILE" 2>/dev/null; then
                total_zombies=$(jq -r '.total_zombies // 0' "$STATS_FILE" 2>/dev/null || echo 0)
                cleaned_zombies=$(jq -r '.cleaned_zombies // 0' "$STATS_FILE" 2>/dev/null || echo 0)
                
                # Sanity check on loaded values
                if ! [[ "$total_zombies" =~ ^[0-9]+$ ]]; then total_zombies=0; fi
                if ! [[ "$cleaned_zombies" =~ ^[0-9]+$ ]]; then cleaned_zombies=0; fi
                
                # Cap values to prevent integer overflow
                if [ "$total_zombies" -gt 1000000 ]; then total_zombies=1000000; fi
                if [ "$cleaned_zombies" -gt 1000000 ]; then cleaned_zombies=1000000; fi
            else
                # JSON is invalid, reset stats
                total_zombies=0
                cleaned_zombies=0
                log_message "Invalid stats file detected, resetting stats" "CRITICAL"
            fi
        else
            # No jq available, use defaults
            total_zombies=0
            cleaned_zombies=0
        fi
    else
        # File doesn't exist or is too large
        total_zombies=0
        cleaned_zombies=0
    fi
}

# Update stats with atomic file operations
update_stats() {
    local pid=$1
    local ppid=$2
    local cmd=$3
    
    # Increment counters with overflow protection
    if [ "$total_zombies" -lt 1000000 ]; then
        total_zombies=$((total_zombies + 1))
    fi
    
    if [ "$cleaned_zombies" -lt 1000000 ]; then
        cleaned_zombies=$((cleaned_zombies + 1))
    fi
    
    # Create temp file for atomic write
    local tmp_file=$(mktemp)
    if [ -n "$tmp_file" ] && [ -w "$tmp_file" ]; then
        # Use jq if available for proper JSON handling
        if command -v jq >/dev/null 2>&1; then
            jq -n \
               --arg total "$total_zombies" \
               --arg cleaned "$cleaned_zombies" \
               --arg time "$(date -Iseconds)" \
            '{
                "total_zombies": ($total|tonumber),
                "cleaned_zombies": ($cleaned|tonumber),
                "last_update": $time
             }' > "$tmp_file" 2>/dev/null
        else
            # Simple fallback if jq not available
            echo "{\"total_zombies\":$total_zombies,\"cleaned_zombies\":$cleaned_zombies,\"last_update\":\"$(date -Iseconds)\"}" > "$tmp_file"
        fi
        
        # Atomic update with size check
        if [ -s "$tmp_file" ] && [ $(stat -c%s "$tmp_file" 2>/dev/null || echo 0) -lt 4096 ]; then
            mv "$tmp_file" "$STATS_FILE" 2>/dev/null
            chmod 640 "$STATS_FILE" 2>/dev/null
        else
            rm -f "$tmp_file"
        fi
    fi
}

# Optimized zombie process detection with improved performance
get_zombies() {
    local zombies=""
    local count=0
    
    # Method 1: Direct /proc scanning with optimized approach (most efficient)
    # Create a temporary file to hold zombie PIDs for parallel processing
    local tmp_zombies=$(mktemp)
    if [ -n "$tmp_zombies" ] && [ -w "$tmp_zombies" ]; then
        # First pass: quickly identify zombie processes
        /bin/grep -l "^State:[[:space:]]*Z" /proc/[0-9]*/status 2>/dev/null | 
            /bin/sed -e 's|/proc/\([0-9]*\)/status|\1|' > "$tmp_zombies"
        
        # Check if we found any zombies
        if [ -s "$tmp_zombies" ]; then
            # Process each zombie in a more efficient manner
            while read -r pid && [ "$count" -lt "$MAX_ZOMBIES_PER_SCAN" ]; do
                # Use common function to get parent PID
                if [ -f "/usr/local/bin/common_functions.sh" ]; then
                    # Use common function if available
                    local ppid=$(sid_get_process_info "$pid" "ppid")
                    local cmd=$(sid_get_process_info "$pid" "cmd")
                else
                    # Fallback to direct extraction
                    local ppid=$(/usr/bin/awk '{print $4}' "/proc/$pid/stat" 2>/dev/null)
                    local cmd=$(/bin/cat "/proc/$pid/cmdline" 2>/dev/null | /usr/bin/tr '\0' ' ' | /usr/bin/head -c 100)
                fi
                
                # Validate pid and ppid are numeric
                if [[ "$pid" =~ ^[0-9]+$ ]] && [[ "$ppid" =~ ^[0-9]+$ ]]; then
                    zombies="${zombies}${pid}:${ppid}:${cmd}\n"
                    count=$((count + 1))
                fi
            done < "$tmp_zombies"
        fi
        
        # Clean up
        /bin/rm -f "$tmp_zombies"
    fi
    
    # Method 2: Use ps as fallback if no zombies found yet (less efficient but more compatible)
    if [ -z "$zombies" ]; then
        # Use optimized ps command with minimal output format
        local ps_zombies=$(/bin/ps axo pid,stat,ppid --no-headers | /bin/grep -E '^\s*[0-9]+\s+Z' | 
                          /usr/bin/head -n $MAX_ZOMBIES_PER_SCAN)
        
        if [ -n "$ps_zombies" ]; then
            while read -r line && [ "$count" -lt "$MAX_ZOMBIES_PER_SCAN" ]; do
                # Extract fields with more robust method
                local fields=($line)
                local pid="${fields[0]}"
                local ppid="${fields[2]}"
                
                # Get command separately to avoid parsing issues
                local cmd=""
                if [ -f "/proc/$pid/cmdline" ]; then
                    cmd=$(/bin/cat "/proc/$pid/cmdline" 2>/dev/null | /usr/bin/tr '\0' ' ' | /usr/bin/head -c 100)
                fi
                
                # Validate pid and ppid are numeric
                if [[ "$pid" =~ ^[0-9]+$ ]] && [[ "$ppid" =~ ^[0-9]+$ ]]; then
                    zombies="${zombies}${pid}:${ppid}:${cmd}\n"
                    count=$((count + 1))
                fi
            done <<< "$ps_zombies"
        fi
    fi
    
    # Return with safe output and size limit
    echo -e "${zombies:0:$MAX_BUFFER_SIZE}"
}

# Update history with size limits and atomic operations
update_history() {
    local pid=$1
    local ppid=$2
    local cmd=$3
    local action=$4
    
    # Truncate command to prevent buffer overflow
    cmd="${cmd:0:100}"
    
    # Create temp file for atomic write
    local tmp_file=$(mktemp)
    if [ -n "$tmp_file" ] && [ -w "$tmp_file" ]; then
        if command -v jq >/dev/null 2>&1 && [ -f "$HISTORY_FILE" ] && [ $(stat -c%s "$HISTORY_FILE" 2>/dev/null || echo 0) -lt 1048576 ]; then
            # Validate JSON before processing
            if jq empty "$HISTORY_FILE" 2>/dev/null; then
                # Add new entry and prune old entries
                jq --arg pid "$pid" \
                   --arg ppid "$ppid" \
                   --arg cmd "$cmd" \
                   --arg action "$action" \
                   --arg time "$(date -Iseconds)" \
                   --argjson max "$MAX_HISTORY_SIZE" \
                '.entries = ([{
                    "pid": $pid,
                    "ppid": $ppid,
                    "cmd": $cmd,
                    "action": $action,
                    "timestamp": $time
                }] + (.entries // [])) | .entries[0:$max] | {entries: .}' \
                "$HISTORY_FILE" > "$tmp_file" 2>/dev/null
            else
                # JSON is invalid, create new history
                echo "{\"entries\":[{\"pid\":\"$pid\",\"ppid\":\"$ppid\",\"cmd\":\"$cmd\",\"action\":\"$action\",\"timestamp\":\"$(date -Iseconds)\"}]}" > "$tmp_file"
            fi
        else
            # No jq or file too large, create new history
            echo "{\"entries\":[{\"pid\":\"$pid\",\"ppid\":\"$ppid\",\"cmd\":\"$cmd\",\"action\":\"$action\",\"timestamp\":\"$(date -Iseconds)\"}]}" > "$tmp_file"
        fi
        
        # Atomic update with size check
        if [ -s "$tmp_file" ] && [ $(stat -c%s "$tmp_file" 2>/dev/null || echo 0) -lt 1048576 ]; then
            mv "$tmp_file" "$HISTORY_FILE" 2>/dev/null
            chmod 640 "$HISTORY_FILE" 2>/dev/null
        else
            rm -f "$tmp_file"
        fi
    fi
}

# Safely handle zombie processes with multiple strategies and absolute paths
handle_zombie() {
    local pid=$1
    local ppid=$2
    local cmd=$3
    
    # Validate inputs to prevent injection
    if ! [[ "$pid" =~ ^[0-9]+$ ]] || ! [[ "$ppid" =~ ^[0-9]+$ ]]; then
        log_message "Invalid PID or PPID format: PID=$pid, PPID=$ppid" "CRITICAL"
        return 1
    fi
    
    # Truncate command to prevent buffer overflow
    cmd="${cmd:0:100}"
    
    # Check if zombie still exists before proceeding
    if ! /bin/grep -q "^State:\s*Z" "/proc/$pid/status" 2>/dev/null; then
        log_message "Process PID=$pid is no longer a zombie, skipping" "CRITICAL"
        return 0
    fi
    
    log_message "Processing zombie PID=$pid, PPID=$ppid" "CRITICAL"
    
    # Strategy 1: Send SIGCHLD to parent with timeout
    if /usr/bin/timeout 2s /bin/kill -SIGCHLD "$ppid" 2>/dev/null; then
        /bin/sleep 0.5
        if ! /bin/ps -p "$pid" >/dev/null 2>&1; then
            log_message "Zombie PID=$pid cleaned with SIGCHLD to parent" "CRITICAL"
            update_history "$pid" "$ppid" "$cmd" "cleaned_sigchld"
            update_stats "$pid" "$ppid" "$cmd"
            return 0
        fi
    fi
    
    # Strategy 2: Send SIGCONT to parent with timeout
    if /usr/bin/timeout 2s /bin/kill -SIGCONT "$ppid" 2>/dev/null; then
        /bin/sleep 0.5
        if ! /bin/ps -p "$pid" >/dev/null 2>&1; then
            log_message "Zombie PID=$pid cleaned with SIGCONT to parent" "CRITICAL"
            update_history "$pid" "$ppid" "$cmd" "cleaned_sigcont"
            update_stats "$pid" "$ppid" "$cmd"
            return 0
        fi
    fi
    
    # Strategy 3: Terminate parent if not system critical
    if [ "$ppid" -ne 1 ] && [ "$ppid" -ne 0 ]; then
        # Check if parent still exists
        if ! [ -d "/proc/$ppid" ]; then
            log_message "Parent process PID=$ppid no longer exists" "CRITICAL"
            update_history "$pid" "$ppid" "$cmd" "parent_gone"
            return 1
        fi
        
        # Get parent command with absolute paths
        local parent_cmd=$(/bin/ps -o comm= -p "$ppid" 2>/dev/null)
        
        # Expanded list of critical system processes
        local critical_procs="systemd|init|upstart|kthreadd|rcu_sched|migration|watchdog|kdevtmpfs|kauditd|khungtaskd|ksmd|khugepaged|kswapd|kworker|jbd2|ext4|btrfs|xfs|dm_|md|raid|scsi|usb|irq|sshd|login|getty|agetty|dbus-daemon|NetworkManager|systemd-"
        
        # Check against critical system processes
        if ! [[ "$parent_cmd" =~ ^($critical_procs) ]]; then
            log_message "Terminating parent process PID=$ppid (Command: $parent_cmd) to clean zombie PID=$pid" "CRITICAL"
            
            # First try SIGTERM with timeout
            if /usr/bin/timeout 2s /bin/kill -TERM "$ppid" 2>/dev/null; then
                /bin/sleep 1
                if ! /bin/ps -p "$pid" >/dev/null 2>&1; then
                    log_message "Zombie PID=$pid cleaned by terminating parent with SIGTERM" "CRITICAL"
                    update_history "$pid" "$ppid" "$cmd" "cleaned_parent_term"
                    update_stats "$pid" "$ppid" "$cmd"
                    return 0
                fi
            fi
            
            # If SIGTERM failed, try SIGKILL with timeout
            if /usr/bin/timeout 2s /bin/kill -KILL "$ppid" 2>/dev/null; then
                /bin/sleep 1
                if ! /bin/ps -p "$pid" >/dev/null 2>&1; then
                    log_message "Zombie PID=$pid cleaned by killing parent" "CRITICAL"
                    update_history "$pid" "$ppid" "$cmd" "cleaned_parent_kill"
                    update_stats "$pid" "$ppid" "$cmd"
                    return 0
                fi
            fi
        } else {
            log_message "Parent PID=$ppid is a critical system process ($parent_cmd), not terminating" "CRITICAL"
        }
    fi
    
    log_message "Failed to clean zombie PID=$pid (parent PID=$ppid)" "CRITICAL"
    update_history "$pid" "$ppid" "$cmd" "failed_cleaning"
    return 1
}

# Check for repeat zombie creators with memory-safe processing
check_zombie_patterns() {
    if command -v jq >/dev/null 2>&1 && [ -f "$STATS_FILE" ] && [ -f "$HISTORY_FILE" ]; then
        # Validate JSON before processing
        if jq empty "$HISTORY_FILE" 2>/dev/null; then
            # Find repeat offenders (parents creating multiple zombies)
            local repeat_parents=$(jq -r '.entries | group_by(.ppid) | map({ppid: .[0].ppid, count: length}) | sort_by(.count) | reverse | .[0:5] | .[] | select(.count > 2) | "\(.ppid):\(.count)"' "$HISTORY_FILE" 2>/dev/null)
            
            if [ -n "$repeat_parents" ]; then
                log_message "Detected repeat zombie creators:" "CRITICAL"
                while IFS=: read -r ppid count; do
                    if [[ "$ppid" =~ ^[0-9]+$ ]] && ps -p "$ppid" >/dev/null 2>&1; then
                        local cmd=$(ps -o cmd= -p "$ppid" 2>/dev/null | head -c 100)
                        log_message "  PPID=$ppid (Command: $cmd) has created $count zombies" "CRITICAL"
                    fi
                done <<< "$repeat_parents"
            fi
        fi
    fi
}

# Generate health report with memory-safe processing
generate_health_report() {
    # Load current stats
    load_stats
    
    # Calculate success rate with division by zero protection
    local success_rate=0
    if [ "$total_zombies" -gt 0 ]; then
        success_rate=$((cleaned_zombies * 100 / total_zombies))
    fi
    
    log_message "Zombie Process Hunter Health Report:" "CRITICAL"
    log_message "  Total zombies detected: $total_zombies" "CRITICAL"
    log_message "  Zombies cleaned: $cleaned_zombies" "CRITICAL"
    log_message "  Success rate: $success_rate%" "CRITICAL"
    
    # Check for recent activity with safe JSON processing
    if command -v jq >/dev/null 2>&1 && [ -f "$HISTORY_FILE" ]; then
        # Validate JSON before processing
        if jq empty "$HISTORY_FILE" 2>/dev/null; then
            local recent_count=$(jq '.entries | length' "$HISTORY_FILE" 2>/dev/null || echo 0)
            if [ "$recent_count" -gt 0 ]; then
                log_message "  Recent activity: $recent_count entries in history" "CRITICAL"
            fi
        fi
    fi
}

# Initialize variables with safe defaults
total_zombies=0
cleaned_zombies=0
counter=0
health_report_interval=12

# Load stats at startup
load_stats

# Main loop with memory leak prevention, enhanced security, and absolute paths
main() {
    log_message "Zombie Process Hunter Hardened Fangbull started" "CRITICAL"
    
    # Use lower CPU priority and IO priority with absolute paths
    /usr/bin/renice 10 $$ > /dev/null 2>&1
    /usr/bin/ionice -c3 -p $$ > /dev/null 2>&1
    
    # Set resource limits to prevent memory bloat
    ulimit -v 104857600 2>/dev/null  # Virtual memory limit: 100MB
    ulimit -t 3600 2>/dev/null       # CPU time limit: 1 hour
    ulimit -n 1024 2>/dev/null       # File descriptor limit
    
    while true; do
        # Get zombies with safety limit
        local zombie_list=$(get_zombies)
        local zombie_count=0
        
        # Process zombies with controlled iteration
        if [ -n "$zombie_list" ]; then
            # Use a temporary file for processing to avoid command substitution issues
            local tmp_file=$(mktemp)
            if [ -n "$tmp_file" ] && [ -w "$tmp_file" ]; then
                echo "$zombie_list" > "$tmp_file"
                
                while IFS=: read -r pid ppid cmd; do
                    # Skip invalid entries and enforce limits
                    if [ -n "$pid" ] && [ -n "$ppid" ] && [[ "$pid" =~ ^[0-9]+$ ]] && [[ "$ppid" =~ ^[0-9]+$ ]] && [ "$zombie_count" -lt "$MAX_ZOMBIES_PER_SCAN" ]; then
                        # Use function call directly instead of bash -c for better security
                        (
                            # Create subshell with timeout for isolation
                            /usr/bin/timeout 10s /bin/sh -c "
                                # Validate inputs again for extra security
                                if [[ \"$pid\" =~ ^[0-9]+$ ]] && [[ \"$ppid\" =~ ^[0-9]+$ ]]; then
                                    handle_zombie \"$pid\" \"$ppid\" \"${cmd//\"/\\\"}\"
                                fi
                            "
                        )
                        zombie_count=$((zombie_count + 1))
                    fi
                done < "$tmp_file"
                
                # Clean up temporary file
                /bin/rm -f "$tmp_file"
            else
                log_message "ERROR: Could not create temporary file for zombie processing" "CRITICAL"
            fi
            
            # Alert on high zombie count
            if [ "$zombie_count" -gt "$ALERT_THRESHOLD" ]; then
                log_message "WARNING: High number of zombies detected ($zombie_count)" "CRITICAL"
                check_zombie_patterns
            fi
        fi
        
        # Periodic maintenance with counter overflow protection
        counter=$((counter % 1000000 + 1))
        
        # Generate health report periodically
        if [ $((counter % health_report_interval)) -eq 0 ]; then
            generate_health_report
        fi
        
        # Adaptive sleep based on system load
        if [ "$zombie_count" -gt 5 ]; then
            /bin/sleep 30
        else
            /bin/sleep $SCAN_INTERVAL
        fi
        
        # Enhanced aggressive memory management with tiered approach
        if [ $((counter % 25)) -eq 0 ]; then  # More frequent checks (every 25 cycles)
            # Check memory usage with more accurate method
            local mem_usage=$(/bin/ps -o rss= -p $$ 2>/dev/null || echo 0)
            local mem_threshold_warn=30720   # 30MB warning threshold
            local mem_threshold_crit=40960   # 40MB critical threshold
            
            # Always perform basic cleanup regardless of memory usage
            # Force garbage collection for temporary variables
            unset zombie_list
            
            # Level 1 cleanup (always do this)
            if [ -n "${CLEAN_CACHE[*]}" ]; then
                # Clear any cached data older than 10 minutes
                local current_time=$(/bin/date +%s)
                local cutoff_time=$((current_time - 600))
                
                # Find and remove old cache entries
                for key in "${!CLEAN_CACHE[@]}"; do
                    local entry_time=${CLEAN_CACHE[$key]%%:*}
                    if [ "$entry_time" -lt "$cutoff_time" ]; then
                        unset CLEAN_CACHE["$key"]
                    fi
                done
            fi
            
            # Level 2 cleanup (warning level memory usage)
            if [ "$mem_usage" -gt "$mem_threshold_warn" ]; then
                log_message "Warning: High memory usage detected: $((mem_usage/1024)) MB, performing standard cleanup" "CRITICAL"
                
                # Clean up history if somewhat large
                if [ -f "$HISTORY_FILE" ] && [ $(/bin/stat -c%s "$HISTORY_FILE" 2>/dev/null || echo 0) -gt 524288 ]; then  # 512KB
                    log_message "History file growing large, pruning old entries" "CRITICAL"
                    # Create a new history with just the last 200 entries
                    if command -v jq >/dev/null 2>&1; then
                        /usr/bin/jq '.entries | sort_by(.timestamp) | reverse | .[0:200] | {entries: .}' "$HISTORY_FILE" > "$HISTORY_FILE.new"
                        if [ -s "$HISTORY_FILE.new" ]; then
                            /bin/mv "$HISTORY_FILE.new" "$HISTORY_FILE"
                            /bin/chmod 640 "$HISTORY_FILE"
                        fi
                    fi
                fi
                
                # Clear more variables
                unset zombie_count
                unset mem_threshold_warn
            fi
            
            # Level 3 cleanup (critical level memory usage)
            if [ "$mem_usage" -gt "$mem_threshold_crit" ]; then
                log_message "CRITICAL: Very high memory usage detected: $((mem_usage/1024)) MB, performing aggressive cleanup" "CRITICAL"
                
                # Aggressively clean up history
                if [ -f "$HISTORY_FILE" ]; then
                    log_message "Performing aggressive history cleanup" "CRITICAL"
                    # Create a minimal history with just the last 50 entries
                    if command -v jq >/dev/null 2>&1; then
                        /usr/bin/jq '.entries | sort_by(.timestamp) | reverse | .[0:50] | {entries: .}' "$HISTORY_FILE" > "$HISTORY_FILE.new"
                        if [ -s "$HISTORY_FILE.new" ]; then
                            /bin/mv "$HISTORY_FILE.new" "$HISTORY_FILE"
                            /bin/chmod 640 "$HISTORY_FILE"
                        fi
                    fi
                fi
                
                # Clean up stats file if it exists and is large
                if [ -f "$STATS_FILE" ] && [ $(/bin/stat -c%s "$STATS_FILE" 2>/dev/null || echo 0) -gt 262144 ]; then  # 256KB
                    log_message "Stats file too large, resetting" "CRITICAL"
                    echo "{\"total_zombies\":$total_zombies,\"cleaned_zombies\":$cleaned_zombies,\"last_update\":\"$(date -Iseconds)\"}" > "$STATS_FILE"
                    chmod 640 "$STATS_FILE" 2>/dev/null
                fi
                
                # Reset all non-essential variables
                unset mem_threshold_crit
                unset current_time
                unset cutoff_time
                
                # Request garbage collection from system
                sleep 0.1
            fi
            
            # Final cleanup
            unset mem_usage
        fi
    done
}

# Trap signals for clean exit and reporting with proper cleanup
trap 'generate_health_report; log_message "Zombie Process Hunter Hardened Fangbull stopped" "CRITICAL"; exit 0' SIGTERM SIGINT SIGHUP

main 